{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import rand, col\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\n",
    "\n",
    "seed = 100\n",
    "filePath = \"Organized_dataset/cleaned/review_cleaned.csv\"\n",
    "sc = SparkContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhouzihui/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3057: DtypeWarning: Columns (0,1) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>GJXCdrto3ASJOqKeVWPi6Q</td>\n",
       "      <td>I *adore* Travis at the Hard Rock's new Kelly ...</td>\n",
       "      <td>NZnhc2sEQy3RmzKTZnqtwQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-01-14 21:30:33</td>\n",
       "      <td>yXQM5uF2jS6es16SJzNHfg</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2TzJjDVDEuAW6MR5Vuc1ug</td>\n",
       "      <td>I have to say that this office really has it t...</td>\n",
       "      <td>WTqjgwHlXbSFevF32_DJVw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2016-11-09 20:09:03</td>\n",
       "      <td>n6-Gk65cPZL6Uz8qRm3NYw</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>G7XHMxG0bx9oBJNECG4IFg</td>\n",
       "      <td>Tracy dessert had a big name in Hong Kong and ...</td>\n",
       "      <td>3fw2X5bZYeW9xCz_zGhOHg</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2016-05-07 01:21:02</td>\n",
       "      <td>jlu4CztcSxrKx56ba1a5AQ</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>svK3nBU7Rk8VfGorlrN52A</td>\n",
       "      <td>You can't really find anything wrong with this...</td>\n",
       "      <td>YvrylyuWgbP90RgMqZQVnQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-04-07 21:27:49</td>\n",
       "      <td>NJlxGtouq06hhC7sS2ECYw</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1wVA2-vQIuW_ClmXkDxqMQ</td>\n",
       "      <td>Great lunch today. Staff was very helpful in a...</td>\n",
       "      <td>NyLYY8q1-H3hfsTwuwLPCg</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2015-01-03 22:47:34</td>\n",
       "      <td>86J5DwcFk4f4In1Vxe2TvA</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      useful               review_id  \\\n",
       "funny                                  \n",
       "0          0  GJXCdrto3ASJOqKeVWPi6Q   \n",
       "0          3  2TzJjDVDEuAW6MR5Vuc1ug   \n",
       "4          5  G7XHMxG0bx9oBJNECG4IFg   \n",
       "0          0  svK3nBU7Rk8VfGorlrN52A   \n",
       "0          0  1wVA2-vQIuW_ClmXkDxqMQ   \n",
       "\n",
       "                                                    text  \\\n",
       "funny                                                      \n",
       "0      I *adore* Travis at the Hard Rock's new Kelly ...   \n",
       "0      I have to say that this office really has it t...   \n",
       "4      Tracy dessert had a big name in Hong Kong and ...   \n",
       "0      You can't really find anything wrong with this...   \n",
       "0      Great lunch today. Staff was very helpful in a...   \n",
       "\n",
       "                  business_id  stars                 date  \\\n",
       "funny                                                       \n",
       "0      NZnhc2sEQy3RmzKTZnqtwQ    5.0  2017-01-14 21:30:33   \n",
       "0      WTqjgwHlXbSFevF32_DJVw    5.0  2016-11-09 20:09:03   \n",
       "4      3fw2X5bZYeW9xCz_zGhOHg    3.0  2016-05-07 01:21:02   \n",
       "0      YvrylyuWgbP90RgMqZQVnQ    5.0  2017-04-07 21:27:49   \n",
       "0      NyLYY8q1-H3hfsTwuwLPCg    4.0  2015-01-03 22:47:34   \n",
       "\n",
       "                      user_id  cool  \n",
       "funny                                \n",
       "0      yXQM5uF2jS6es16SJzNHfg   0.0  \n",
       "0      n6-Gk65cPZL6Uz8qRm3NYw   0.0  \n",
       "4      jlu4CztcSxrKx56ba1a5AQ   5.0  \n",
       "0      NJlxGtouq06hhC7sS2ECYw   0.0  \n",
       "0      86J5DwcFk4f4In1Vxe2TvA   0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPandas = pd.read_csv(filePath, index_col=0)\n",
    "dfPandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3148044, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfPandas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs:  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>useful</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>funny</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>OSdqcxyXqM-XTEgajJNUmw</td>\n",
       "      <td>Working with Tina and Marcia has been such a p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My husband and I had not purchased a home before and we definitely needed some hand holding. They were patient and professional. We got our dream home and the entire experience was awesome! Thank you so much ladies for a job well done!</th>\n",
       "      <td>eO0Dsp8MBjUT16lno8gkmA</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2017-02-22 01:24:23</td>\n",
       "      <td>QRn8ELZmvP8S4evnSRU9bQ</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    useful  \\\n",
       "funny                                                                        \n",
       "0                                                                        0   \n",
       "My husband and I had not purchased a home befor...  eO0Dsp8MBjUT16lno8gkmA   \n",
       "\n",
       "                                                                 review_id  \\\n",
       "funny                                                                        \n",
       "0                                                   OSdqcxyXqM-XTEgajJNUmw   \n",
       "My husband and I had not purchased a home befor...                     5.0   \n",
       "\n",
       "                                                                                                 text  \\\n",
       "funny                                                                                                   \n",
       "0                                                   Working with Tina and Marcia has been such a p...   \n",
       "My husband and I had not purchased a home befor...                                2017-02-22 01:24:23   \n",
       "\n",
       "                                                               business_id  \\\n",
       "funny                                                                        \n",
       "0                                                                      NaN   \n",
       "My husband and I had not purchased a home befor...  QRn8ELZmvP8S4evnSRU9bQ   \n",
       "\n",
       "                                                    stars date user_id  cool  \n",
       "funny                                                                         \n",
       "0                                                     NaN  NaN     NaN   NaN  \n",
       "My husband and I had not purchased a home befor...    0.0  NaN     NaN   NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"NaNs: \", dfPandas['text'].isnull().sum())\n",
    "dfPandas.loc[dfPandas.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                lowercase=True, max_df=0.95, max_features=None, min_df=0.05,\n",
       "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vectorizer = CountVectorizer(max_df=0.95, min_df=0.05) # Ignore the term that appears in more than 95% of the documents, and less than 5% of the documents\n",
    "count_vectorizer.fit(dfPandas['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfTransformer(norm='l2', smooth_idf=True, sublinear_tf=False, use_idf=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(count_vectorizer.transform(dfPandas['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " 'about',\n",
       " 'after',\n",
       " 'again',\n",
       " 'all',\n",
       " 'also',\n",
       " 'always',\n",
       " 'am',\n",
       " 'amazing',\n",
       " 'an',\n",
       " 'and',\n",
       " 'another',\n",
       " 'any',\n",
       " 'are',\n",
       " 'area',\n",
       " 'around',\n",
       " 'as',\n",
       " 'asked',\n",
       " 'at',\n",
       " 'away',\n",
       " 'awesome',\n",
       " 'back',\n",
       " 'bad',\n",
       " 'bar',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'best',\n",
       " 'better',\n",
       " 'big',\n",
       " 'bit',\n",
       " 'both',\n",
       " 'busy',\n",
       " 'but',\n",
       " 'by',\n",
       " 'came',\n",
       " 'can',\n",
       " 'check',\n",
       " 'cheese',\n",
       " 'chicken',\n",
       " 'clean',\n",
       " 'come',\n",
       " 'coming',\n",
       " 'could',\n",
       " 'customer',\n",
       " 'day',\n",
       " 'definitely',\n",
       " 'delicious',\n",
       " 'did',\n",
       " 'didn',\n",
       " 'different',\n",
       " 'dinner',\n",
       " 'do',\n",
       " 'don',\n",
       " 'done',\n",
       " 'down',\n",
       " 'drinks',\n",
       " 'eat',\n",
       " 'enough',\n",
       " 'even',\n",
       " 'ever',\n",
       " 'every',\n",
       " 'everything',\n",
       " 'excellent',\n",
       " 'experience',\n",
       " 'favorite',\n",
       " 'feel',\n",
       " 'few',\n",
       " 'find',\n",
       " 'first',\n",
       " 'food',\n",
       " 'for',\n",
       " 'found',\n",
       " 'fresh',\n",
       " 'friendly',\n",
       " 'from',\n",
       " 'get',\n",
       " 'give',\n",
       " 'go',\n",
       " 'going',\n",
       " 'good',\n",
       " 'got',\n",
       " 'great',\n",
       " 'had',\n",
       " 'happy',\n",
       " 'has',\n",
       " 'have',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'highly',\n",
       " 'his',\n",
       " 'home',\n",
       " 'hot',\n",
       " 'how',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'it',\n",
       " 'just',\n",
       " 'know',\n",
       " 'last',\n",
       " 'like',\n",
       " 'little',\n",
       " 'll',\n",
       " 'location',\n",
       " 'long',\n",
       " 'looking',\n",
       " 'lot',\n",
       " 'love',\n",
       " 'lunch',\n",
       " 'made',\n",
       " 'make',\n",
       " 'many',\n",
       " 'me',\n",
       " 'meal',\n",
       " 'menu',\n",
       " 'minutes',\n",
       " 'more',\n",
       " 'most',\n",
       " 'much',\n",
       " 'my',\n",
       " 'need',\n",
       " 'never',\n",
       " 'new',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'night',\n",
       " 'no',\n",
       " 'not',\n",
       " 'nothing',\n",
       " 'now',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'one',\n",
       " 'only',\n",
       " 'or',\n",
       " 'order',\n",
       " 'ordered',\n",
       " 'other',\n",
       " 'our',\n",
       " 'out',\n",
       " 'over',\n",
       " 'overall',\n",
       " 'people',\n",
       " 'place',\n",
       " 'pretty',\n",
       " 'price',\n",
       " 'prices',\n",
       " 'quality',\n",
       " 're',\n",
       " 'really',\n",
       " 'recommend',\n",
       " 'restaurant',\n",
       " 'right',\n",
       " 'said',\n",
       " 'salad',\n",
       " 'same',\n",
       " 'sauce',\n",
       " 'say',\n",
       " 'see',\n",
       " 'service',\n",
       " 'she',\n",
       " 'should',\n",
       " 'side',\n",
       " 'since',\n",
       " 'small',\n",
       " 'so',\n",
       " 'some',\n",
       " 'something',\n",
       " 'staff',\n",
       " 'stars',\n",
       " 'still',\n",
       " 'super',\n",
       " 'sure',\n",
       " 'table',\n",
       " 'take',\n",
       " 'taste',\n",
       " 'than',\n",
       " 'that',\n",
       " 'the',\n",
       " 'their',\n",
       " 'them',\n",
       " 'then',\n",
       " 'there',\n",
       " 'they',\n",
       " 'thing',\n",
       " 'things',\n",
       " 'think',\n",
       " 'this',\n",
       " 'though',\n",
       " 'time',\n",
       " 'times',\n",
       " 'to',\n",
       " 'told',\n",
       " 'too',\n",
       " 'took',\n",
       " 'tried',\n",
       " 'try',\n",
       " 'two',\n",
       " 'up',\n",
       " 'us',\n",
       " 've',\n",
       " 'vegas',\n",
       " 'very',\n",
       " 'visit',\n",
       " 'wait',\n",
       " 'want',\n",
       " 'wanted',\n",
       " 'was',\n",
       " 'wasn',\n",
       " 'way',\n",
       " 'we',\n",
       " 'well',\n",
       " 'went',\n",
       " 'were',\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'will',\n",
       " 'with',\n",
       " 'work',\n",
       " 'worth',\n",
       " 'would',\n",
       " 'years',\n",
       " 'you',\n",
       " 'your']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = tfidf_transformer.transform(count_vectorizer.transform(dfPandas['text']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3148044x234 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 114857449 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(count_vectorizer, open('Organized_dataset/cleaned/countVectorizer.pkl', 'wb'))\n",
    "pickle.dump(tfidf_transformer, open('Organized_dataset/cleaned/tfidfTransformer.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "scipy.sparse.save_npz('Organized_dataset/cleaned/textTransform.npz', tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMatrix = pd.DataFrame(\n",
    "    data=tfidf.toarray(),\n",
    "    columns=count_vectorizer.get_feature_names(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>10</th>\n",
       "      <th>about</th>\n",
       "      <th>after</th>\n",
       "      <th>again</th>\n",
       "      <th>all</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>am</th>\n",
       "      <th>amazing</th>\n",
       "      <th>an</th>\n",
       "      <th>...</th>\n",
       "      <th>while</th>\n",
       "      <th>who</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>work</th>\n",
       "      <th>worth</th>\n",
       "      <th>would</th>\n",
       "      <th>years</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.051035</td>\n",
       "      <td>0.06043</td>\n",
       "      <td>0.06782</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055916</td>\n",
       "      <td>0.115414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.082211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 234 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    10  about  after  again       all     also   always   am  amazing   an  \\\n",
       "0  0.0    0.0    0.0    0.0  0.051035  0.06043  0.06782  0.0      0.0  0.0   \n",
       "\n",
       "   ...  while  who      will      with  work     worth  would  years      you  \\\n",
       "0  ...    0.0  0.0  0.055916  0.115414   0.0  0.082211    0.0    0.0  0.16944   \n",
       "\n",
       "   your  \n",
       "0   0.0  \n",
       "\n",
       "[1 rows x 234 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoreMatrix.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoreMatrix.to_csv('Organized_dataset/cleaned/textTransformPandas.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.functions import rand, col\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 100\n",
    "# sc = SparkContext()\n",
    "# Already existed, no need to write them again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath = \"Organized_dataset/cleaned/yelp_ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o22.addFile.\n: java.io.FileNotFoundException: File file:/Users/zhouzihui/Desktop/Columbia/2019%20Fall/Personalization/Homework/2_Final%20Project/Organized_dataset/cleaned/yelp_ratings.csv does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)\n\tat org.apache.spark.SparkContext.addFile(SparkContext.scala:1544)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-cf898c924fa5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# read dataset into spark RDD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msqlContext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSQLContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m df = sqlContext.read.csv(\n\u001b[1;32m      5\u001b[0m     \u001b[0mSparkFiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yelp_ratings.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36maddFile\u001b[0;34m(self, path, recursive)\u001b[0m\n\u001b[1;32m    914\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m         \"\"\"\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0maddPyFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    326\u001b[0m                 raise Py4JJavaError(\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 raise Py4JError(\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o22.addFile.\n: java.io.FileNotFoundException: File file:/Users/zhouzihui/Desktop/Columbia/2019%20Fall/Personalization/Homework/2_Final%20Project/Organized_dataset/cleaned/yelp_ratings.csv does not exist\n\tat org.apache.hadoop.fs.RawLocalFileSystem.deprecatedGetFileStatus(RawLocalFileSystem.java:611)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileLinkStatusInternal(RawLocalFileSystem.java:824)\n\tat org.apache.hadoop.fs.RawLocalFileSystem.getFileStatus(RawLocalFileSystem.java:601)\n\tat org.apache.hadoop.fs.FilterFileSystem.getFileStatus(FilterFileSystem.java:421)\n\tat org.apache.spark.SparkContext.addFile(SparkContext.scala:1544)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:745)\n"
     ]
    }
   ],
   "source": [
    "# read dataset into spark RDD\n",
    "sc.addFile(filePath)\n",
    "sqlContext = SQLContext(sc)\n",
    "df = sqlContext.read.csv(\n",
    "    SparkFiles.get(\"yelp_ratings.csv\"), \n",
    "    header=True, \n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "sqlContext.registerDataFrameAsTable(df, \"df\")\n",
    "df = sqlContext.sql('''\n",
    "    SELECT *\n",
    "    FROM df\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = df.where(col('TrainTest') == 1)\n",
    "dftest = df.where(col('TrainTest') == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftest.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import operator\n",
    "# using average rate as Baseline model\n",
    "meanRating = df.rdd.map(lambda x: x[2]).mean()\n",
    "baselineRmse = math.sqrt(\n",
    "    dftest.rdd.map(lambda x: (meanRating - x[2]) ** 2).reduce(operator.add) / dftest.count()\n",
    ")\n",
    "print(\"Baseline Model (Rating Average for all users and movies) Performance on Test Set\")\n",
    "print(\"baseline performance on test set: \", baselineRmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
