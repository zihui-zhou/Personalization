{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "\n",
    "## Personalization - Homework#1\n",
    "#### Zihui Zhou, zz2694@columbia.edu (uni: zz2694)\n",
    "\n",
    "Answer to each question iswritten in the green box below. <br>\n",
    "The homework is collaborated with Yi-ping Tseng (yt2690).\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "• Download and load the data set for red wine into a data frame:  http://archive.ics.uci.edu/ml/datasets/Wine+Quality  (Use only the red wine data, not the white wine data) </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('winequality-red.csv', sep=';') # Setting the separator to semi-colon to separate the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> • Split the data by columns into features that you will use for prediction, X, and the feature you will try to predict (‘quality’), y </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = df.shape[1] - 1 \n",
    "dfs = np.split(df, [a], axis=1)\n",
    "X = dfs[0]\n",
    "y = dfs[1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\"> • Split both X and y by rows into training sets and testing sets: Randomly split the data, keeping 80% of instances for training and 20% for testing -- At the end, you should have 4 data sets: X_train, y_train, X_test, and y_test </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>10.8</td>\n",
       "      <td>0.470</td>\n",
       "      <td>0.43</td>\n",
       "      <td>2.10</td>\n",
       "      <td>0.171</td>\n",
       "      <td>27.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.76</td>\n",
       "      <td>10.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.10</td>\n",
       "      <td>0.095</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99854</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.53</td>\n",
       "      <td>9.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>9.1</td>\n",
       "      <td>0.290</td>\n",
       "      <td>0.33</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.063</td>\n",
       "      <td>13.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.99516</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.84</td>\n",
       "      <td>11.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>10.2</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.053</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.99820</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.42</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>12.2</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.49</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.075</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.99690</td>\n",
       "      <td>3.13</td>\n",
       "      <td>0.63</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "1109           10.8             0.470         0.43            2.10      0.171   \n",
       "1032            8.1             0.820         0.00            4.10      0.095   \n",
       "1002            9.1             0.290         0.33            2.05      0.063   \n",
       "487            10.2             0.645         0.36            1.80      0.053   \n",
       "979            12.2             0.450         0.49            1.40      0.075   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "1109                 27.0                  66.0  0.99820  3.17       0.76   \n",
       "1032                  5.0                  14.0  0.99854  3.36       0.53   \n",
       "1002                 13.0                  27.0  0.99516  3.26       0.84   \n",
       "487                   5.0                  14.0  0.99820  3.17       0.42   \n",
       "979                   3.0                   6.0  0.99690  3.13       0.63   \n",
       "\n",
       "      alcohol  \n",
       "1109     10.8  \n",
       "1032      9.6  \n",
       "1002     11.7  \n",
       "487      10.0  \n",
       "979      10.4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X.sample(frac=0.8, random_state=0)\n",
    "X_test = X.drop(X_train.index)\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    quality\n",
       "11      5.0\n",
       "23      5.0\n",
       "24      6.0\n",
       "25      5.0\n",
       "28      5.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y.iloc[X_train.index]\n",
    "y_test = y.iloc[X_test.index]\n",
    "y_train.head()\n",
    "y_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression equations and functions\n",
    "\n",
    "<div class=\"alert alert-block alert-info\"> • Write out two equations: (1) the equation for a the linear model that predicts y from X, and (2) the equation for computing the Residual Sum of Squares (RSS) for the linear model, given data, vector x, and parameters, vector β. <br>  </div>\n",
    "\n",
    "> • See equations 3.1 and 3.2 in the Elements of Statistical Learning book <br>\n",
    "• Feel free to ignore the intercept term for this homework (e.g. β0) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "\n",
    "#### Answer:   \n",
    "1) The linear model is \n",
    "$$\n",
    "     y = \\sum_j x_j \\beta_j + \\beta_0\n",
    "$$\n",
    "2) The residual sum of squares (RSS) \n",
    "$$\n",
    "RSS = \\sum_i (y_i - f(x_i))^2 \n",
    "$$\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• Translate these equations into code in the form of two functions  </div>\n",
    "\n",
    "> •The first function should compute the estimated value of y, which is y_hat, for particular values of x, and β. That is, there should be two arguments, one for the data and one for the linear function parameters. ) <br>\n",
    "• The second function should compute the RSS for the first function <br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(beta, X):\n",
    "    if isinstance(beta, (pd.DataFrame, pd.Series)): # If beta is DataFrame/Series from Pandas, then transform it into numpy arrays\n",
    "        beta = beta.values\n",
    "    \n",
    "    if isinstance(X, (pd.DataFrame, pd.Series)):\n",
    "        index = X.index.values\n",
    "        X = X.values\n",
    "    \n",
    "    if beta.shape[0] - X.shape[1] == 1:\n",
    "        X = np.concatenate([np.ones(shape=(X.shape[0], 1)), X], axis=1)\n",
    "    \n",
    "    return pd.DataFrame(np.matmul(X, beta), index=index, columns=[\"y_hat\"])\n",
    "\n",
    "\n",
    "def RSS(beta, X, y):\n",
    "    pred_y = predict(beta, X)\n",
    "    return np.sum((y.values - pred_y.values)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing the model\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "• Use Scipy’s minimize function to find the value of β that minimize the RSS <br>\n",
    "• https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html <br>\n",
    "• Your call to minimize method will take three arguments: <br> \n",
    "  \n",
    "(1) fun: the RSS function you defined above that you are trying to minimize <br>\n",
    "(2) x0: your initial values of β <br>\n",
    "(3) args: pass in all the data a tuple here. <br><br>\n",
    "\n",
    "\n",
    "For example: <br>\n",
    "• args=(y_train, X_train) <br>\n",
    "• For the second argument you will need to initialize β to some starting value. Try using a random vector with Numpy random methods <br>\n",
    "\n",
    "• numpy.random.normal(0, 1, X_train.shape[1])  <br>\n",
    "• Your final set of functions to fit your model should have the form:\n",
    "           def RSS(beta, X, y):\n",
    " \n",
    "return <some_results>\n",
    "           res = minimize(fun=RSS, x0=beta0, args=(X_train,y_train))\n",
    "           beta_hat = res.x\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.random.normal(0, 1, (X_train.shape[1] + 1, 1))\n",
    "opt = minimize(fun=RSS, x0=beta, args=(X_train, y_train))\n",
    "beta_hat = opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.40628163e+01  8.27834973e-03 -1.11265715e+00 -2.37056254e-01\n",
      "  3.94612173e-03 -1.49863999e+00  3.48265450e-03 -2.94954608e-03\n",
      " -9.30296839e+00 -5.96736860e-01  9.03382746e-01  2.88019940e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "548.7796105427644"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(beta_hat)\n",
    "RSS(beta_hat, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['intercept',\n",
       " 'fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['intercept'] + X_train.columns.values.tolist() # Intercept before the index: Pandas(index -> array -> list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "• What are the qualitative results from your model? Which features seem to be most\n",
    "important? Do you think that the magnitude of the features in X may affect the results (for example, the average total sulfur dioxide across all wines is 46.47, but the average chlorides is only 0.087). </div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "\n",
    "#### Answer:\n",
    "1. The qualitative results are shown as above<br>\n",
    "2. Since 'density' feature has the most negative value of  -9.302968388095524, it seems to be the most important <br>\n",
    "3. Magnitude of features does not influence the wine quality: reading from the above average value, we could not see a relationship between the magnitude and the co-efficient of a feature <br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-9.302968388095524"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amin(beta_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "density                 -9.302968\n",
       "chlorides               -1.498640\n",
       "volatile acidity        -1.112657\n",
       "pH                      -0.596737\n",
       "citric acid             -0.237056\n",
       "total sulfur dioxide    -0.002950\n",
       "free sulfur dioxide      0.003483\n",
       "residual sugar           0.003946\n",
       "fixed acidity            0.008278\n",
       "alcohol                  0.288020\n",
       "sulphates                0.903383\n",
       "intercept               14.062816\n",
       "dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(beta_hat, index=[\"intercept\"] + X_train.columns.values.tolist()).sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chlorides                0.087347\n",
       "citric acid              0.271618\n",
       "volatile acidity         0.525571\n",
       "sulphates                0.655012\n",
       "density                  0.996739\n",
       "residual sugar           2.516341\n",
       "pH                       3.312588\n",
       "fixed acidity            8.310164\n",
       "alcohol                 10.436317\n",
       "free sulfur dioxide     15.868647\n",
       "total sulfur dioxide    46.488663\n",
       "Name: mean, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.describe().loc['mean'].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• How well does your model fit? You should be able to measure the goodness of fit -- RSS, on both the training data and the test data, but only report the results on the test data. In Machine Learning we almost always only care about how well the model fits on data that has not been used to fit the model, because we need to use the model in the future, not the past. Therefore, we only report performance with holdout data, or test data.  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on the test data: 119.3432725445164\n"
     ]
    }
   ],
   "source": [
    "# RSS on the test data\n",
    "RSS_test = RSS(beta_hat, X_test, y_test)\n",
    "print('RSS on the test data:', RSS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• Does the end result or RSS change if you try different initial values of β?  </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "\n",
    "#### Answer:\n",
    "RSS with new β doesn't differentiate a lot from the original RSS, as the following results show.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different initial values of β\n",
    "beta_new0 = np.random.normal(0, 1, (X_train.shape[1] + 1, 1))\n",
    "opt = minimize(fun=RSS, x0=beta_new0, args=(X_train, y_train))\n",
    "beta_hat_new0 = opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training data with new initial value of beta: 548.7796105432501\n",
      "RSS on test data with new initial value of beta: 119.34328533389389\n",
      "Comparison of RSS: 1.278937749304987e-05\n"
     ]
    }
   ],
   "source": [
    "# Apply new beta to RSS\n",
    "RSS_new0_train = RSS(beta_hat_new0, X_train, y_train)\n",
    "RSS_new0_test = RSS(beta_hat_new0, X_test, y_test)\n",
    "print('RSS on training data with new initial value of beta:', RSS_new0_train)\n",
    "print('RSS on test data with new initial value of beta:', RSS_new0_test)\n",
    "print('Comparison of RSS:', RSS_new0_test - RSS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "•  What happens if you change the magnitude of the initial β? </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "    \n",
    "#### Answer:\n",
    "Changing the magnitude of the initial β doesn't have much influence on RSS.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different initial values of β\n",
    "beta_new = np.random.normal(10, 10, (X_train.shape[1] + 1, 1))\n",
    "opt = minimize(fun=RSS, x0=beta_new, args=(X_train, y_train))\n",
    "beta_hat_new = opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training data with new beta: 548.7796105408585\n",
      "RSS on test data with new beta: 119.34326306103756\n"
     ]
    }
   ],
   "source": [
    "# Apply new beta to RSS\n",
    "RSS_new_train = RSS(beta_hat_new, X_train, y_train)\n",
    "RSS_new_test = RSS(beta_hat_new, X_test, y_test)\n",
    "print('RSS on training data with new beta:', RSS_new_train)\n",
    "print('RSS on test data with new beta:', RSS_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training data: 548.7796105427644\n",
      "RSS on test data: 119.3432725445164\n"
     ]
    }
   ],
   "source": [
    "# RSS with original beta\n",
    "RSS_train = RSS(beta_hat, X_train, y_train)\n",
    "RSS_test = RSS(beta_hat, X_test, y_test)\n",
    "print('RSS on training data:', RSS_train)\n",
    "print('RSS on test data:', RSS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• Does the choice of solver method change the end result or RSS? </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "    \n",
    "#### Answer:\n",
    "Trying different methods in the optimize.minimize library, we can see that RSS are different for each method, but do not vary a lot.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training data with new method: 635.590110784124\n",
      "RSS on test data with new method: 134.9063220417022\n"
     ]
    }
   ],
   "source": [
    "opt = minimize(fun=RSS, x0=beta, args=(X_train, y_train), method = 'TNC')\n",
    "beta_hat_method = opt.x\n",
    "RSS_train_method = RSS(beta_hat_method, X_train, y_train)\n",
    "RSS_test_method = RSS(beta_hat_method, X_test, y_test)\n",
    "print('RSS on training data with new method:', RSS_train_method)\n",
    "print('RSS on test data with new method:', RSS_test_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training data with new method: 548.8676614320452\n",
      "RSS on test data with new method: 119.59571084225763\n"
     ]
    }
   ],
   "source": [
    "opt = minimize(fun=RSS, x0=beta, args=(X_train, y_train), method = 'Powell')\n",
    "beta_hat_method = opt.x\n",
    "RSS_train_method = RSS(beta_hat_method, X_train, y_train)\n",
    "RSS_test_method = RSS(beta_hat_method, X_test, y_test)\n",
    "print('RSS on training data with new method:', RSS_train_method)\n",
    "print('RSS on test data with new method:', RSS_test_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS on training data with new method: 548.7796105427644\n",
      "RSS on test data with new method: 119.3432725445164\n"
     ]
    }
   ],
   "source": [
    "opt = minimize(fun=RSS, x0=beta, args=(X_train, y_train), method = 'BFGS')\n",
    "beta_hat_method = opt.x\n",
    "RSS_train_method = RSS(beta_hat_method, X_train, y_train)\n",
    "RSS_test_method = RSS(beta_hat_method, X_test, y_test)\n",
    "print('RSS on training data with new method:', RSS_train_method)\n",
    "print('RSS on test data with new method:', RSS_test_method)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> \n",
    ">\n",
    "\n",
    "# Regularizing the model\n",
    "\n",
    "Regularization seeks to simplify a model by decreasing the model’s complexity and degrees of freedom. While lowering the degrees of freedom also decreases the flexibility of the model, and therefore the performance of the model on training data, it increases generalizability, and thus it often increases performance on test data. One common method of regularization is called shrinkage, and is defined in section 3.4 of Elements of Statistical Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• Try adding in an L2 (aka Ridge) regularization penalty to your model above to create a new, regularized model. See equation 3.41 for guidance. You will need to choose a value of lambda, so start with something small, like 0.01. <br> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge Regression\n",
    "\n",
    "def RSS_L2(beta, X, y, lam):\n",
    "    pred_y = predict(beta, X)\n",
    "    penalty = lam * np.sum(beta[1:]**2)\n",
    "    return np.sum((y.values - pred_y.values)**2) + penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• How does RSS on the training data change? How does RSS on the test data change? <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "    \n",
    "#### Answer:\n",
    "Both RSS on the training data and test data get slightly larger.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.random.normal(0, 1, (X_train.shape[1] + 1, 1))\n",
    "lam = 0.01\n",
    "opt = minimize(fun=RSS_L2, x0=beta, args=(X_train, y_train, lam))\n",
    "beta_hat_L2 = opt.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with Ridge Regression on the training data: 548.8874194420018\n",
      "RSS with Ridge Regression on the test data: 119.58927364152647\n",
      "RSS on training data: 548.7796105427644\n",
      "RSS on test data: 119.3432725445164\n"
     ]
    }
   ],
   "source": [
    "print('RSS with Ridge Regression on the training data:', RSS_L2(beta_hat_L2, X_train, y_train, lam))\n",
    "print('RSS with Ridge Regression on the test data:', RSS_L2(beta_hat_L2, X_test, y_test, lam))\n",
    "# RSS with original beta\n",
    "RSS_train = RSS(beta_hat, X_train, y_train)\n",
    "RSS_test = RSS(beta_hat, X_test, y_test)\n",
    "print('RSS on training data:', RSS_train)\n",
    "print('RSS on test data:', RSS_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• What happens if you try different values of lambda? Can you tune lambda to get the best\n",
    "results on the test data? <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "\n",
    "#### Answer:\n",
    "We can notice that RSS increases with larger lambda, the best result was achieved when lambda is smaller, such as $\\lambda$ = 0.001\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with Ridge Regression on the training data: 548.8210774717589\n",
      "RSS with Ridge Regression on the test data: 119.47404581491647\n"
     ]
    }
   ],
   "source": [
    "lam = 0.001\n",
    "opt = minimize(fun=RSS_L2, x0=beta, args=(X_train, y_train, lam))\n",
    "beta_hat_L2 = opt.x\n",
    "print('RSS with Ridge Regression on the training data:', RSS_L2(beta_hat_L2, X_train, y_train, lam))\n",
    "print('RSS with Ridge Regression on the test data:', RSS_L2(beta_hat_L2, X_test, y_test, lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with Ridge Regression on the training data: 549.3177967429126\n",
      "RSS with Ridge Regression on the test data: 120.11899653645405\n"
     ]
    }
   ],
   "source": [
    "lam = 0.1\n",
    "opt = minimize(fun=RSS_L2, x0=beta, args=(X_train, y_train, lam))\n",
    "beta_hat_L2 = opt.x\n",
    "print('RSS with Ridge Regression on the training data:', RSS_L2(beta_hat_L2, X_train, y_train, lam))\n",
    "print('RSS with Ridge Regression on the test data:', RSS_L2(beta_hat_L2, X_test, y_test, lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with Ridge Regression on the training data: 552.7758931505845\n",
      "RSS with Ridge Regression on the test data: 123.74730733493575\n"
     ]
    }
   ],
   "source": [
    "lam = 1\n",
    "opt = minimize(fun=RSS_L2, x0=beta, args=(X_train, y_train, lam))\n",
    "beta_hat_L2 = opt.x\n",
    "print('RSS with Ridge Regression on the training data:', RSS_L2(beta_hat_L2, X_train, y_train, lam))\n",
    "print('RSS with Ridge Regression on the test data:', RSS_L2(beta_hat_L2, X_test, y_test, lam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• Now try using an L1 (aka Lasso) regularization penalty instead. See equation 3.51 for\n",
    "example. Report your findings on how RSS changes, and if you can roughly tune lambda. <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "    \n",
    "#### Answer:\n",
    "Again, we can notice that RSS increases with larger lambda, the best result was achieved when lambda is smaller, such as $\\lambda$ = 0.001\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso Regression\n",
    "\n",
    "def RSS_L1(beta, X, y, lam):\n",
    "    pred_y = predict(beta, X)\n",
    "    penalty = lam * np.sum(np.absolute(beta[1:]))\n",
    "    return np.sum((y.values - pred_y.values)**2) + penalty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with Lasso Regression on the training data: 548.793233939927\n",
      "RSS with Lasso Regression on the test data: 119.37005336726712\n"
     ]
    }
   ],
   "source": [
    "lam = 0.001\n",
    "opt = minimize(fun=RSS_L1, x0=beta, args=(X_train, y_train, lam))\n",
    "beta_hat_L1 = opt.x\n",
    "print('RSS with Lasso Regression on the training data:', RSS_L1(beta_hat_L1, X_train, y_train, lam))\n",
    "print('RSS with Lasso Regression on the test data:', RSS_L1(beta_hat_L1, X_test, y_test, lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with Lasso Regression on the training data: 548.8854577078587\n",
      "RSS with Lasso Regression on the test data: 119.55767969188275\n"
     ]
    }
   ],
   "source": [
    "lam = 0.01\n",
    "opt = minimize(fun=RSS_L1, x0=beta, args=(X_train, y_train, lam))\n",
    "beta_hat_L1 = opt.x\n",
    "print('RSS with Lasso Regression on the training data:', RSS_L1(beta_hat_L1, X_train, y_train, lam))\n",
    "print('RSS with Lasso Regression on the test data:', RSS_L1(beta_hat_L1, X_test, y_test, lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with Lasso Regression on the training data: 549.3117676532406\n",
      "RSS with Lasso Regression on the test data: 120.02740133532379\n"
     ]
    }
   ],
   "source": [
    "lam = 0.1\n",
    "opt = minimize(fun=RSS_L1, x0=beta, args=(X_train, y_train, lam))\n",
    "beta_hat_L1 = opt.x\n",
    "print('RSS with Lasso Regression on the training data:', RSS_L1(beta_hat_L1, X_train, y_train, lam))\n",
    "print('RSS with Lasso Regression on the test data:', RSS_L1(beta_hat_L1, X_test, y_test, lam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSS with Lasso Regression on the training data: 553.3432492386936\n",
      "RSS with Lasso Regression on the test data: 124.14037483347833\n"
     ]
    }
   ],
   "source": [
    "lam = 1\n",
    "opt = minimize(fun=RSS_L1, x0=beta, args=(X_train, y_train, lam))\n",
    "beta_hat_L1 = opt.x\n",
    "print('RSS with Lasso Regression on the training data:', RSS_L1(beta_hat_L1, X_train, y_train, lam))\n",
    "print('RSS with Lasso Regression on the test data:', RSS_L1(beta_hat_L1, X_test, y_test, lam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "• Again, do you think that the magnitude of the features in X may affect the results with\n",
    "regularization?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\"> \n",
    "    \n",
    "#### Answer:\n",
    "No, since the results with regularization do not depend on the magnitude of the features. Instead, it depends on the importance of the features. Therefore, the magnitude of the features in X do not affect the results with regularization.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
